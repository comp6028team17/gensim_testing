{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lib import jsoncorpus, datastuff\n",
    "import gensim\n",
    "import traceback\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.pipeline\n",
    "import sklearn.preprocessing\n",
    "import sklearn.cross_validation\n",
    "import sklearn.ensemble\n",
    "import sklearn.svm\n",
    "import sklearn.decomposition\n",
    "from lib.scikitComponents import *\n",
    "import itertools\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Load in the previously created corpus and dictionary of scraped sites\n",
    "dictionary, corpus, meta_corpus, dmoz_data = jsoncorpus.load_or_create('docs/sites.jl', stemmed=True, prefix=\"stemmed_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build a list of all topics\n",
    "allcategories = set(tuple(t) for t in dmoz_data['dmoz_categories'])\n",
    "# Build a list of all top-level topics\n",
    "topcategories = set(topic[0] for topic in dmoz_data['dmoz_categories'])\n",
    "# Link topics to URLs\n",
    "meta = list(zip(dmoz_data['urls'], dmoz_data['dmoz_categories']))\n",
    "# Represent the topics in an alternative way\n",
    "heirarchal_categories = lambda max_depth: [['; '.join(topics[:ti+1]) for ti, t in enumerate(topics) if ti < max_depth] for topics in dmoz_data['dmoz_categories']]\n",
    "# Top categories\n",
    "top_categories = [x[0] for x in heirarchal_categories(1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a classification pipeline for the corpus data\n",
    "\n",
    "The Pipeline() object chains together objects from the lib.scikitComponents file, so that they can be used as part of a scikit-learn classification pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a classifier (decision trees), and chain the preprocessing step to the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# classifier = sklearn.svm.LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
    "#      intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
    "#      multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
    "#      verbose=0)\n",
    "\n",
    "# classifier = sklearn.svm.SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3,\n",
    "# gamma=0.0, kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
    "# shrinking=True, tol=0.001, verbose=False)\n",
    "\n",
    "classifier = sklearn.ensemble.ExtraTreesClassifier(random_state=0, n_estimators=100, oob_score=True, bootstrap=True, n_jobs=4)\n",
    "builder = MetaMatrixBuilder(stem=True, use_description=True)\n",
    "clf = sklearn.pipeline.Pipeline([\n",
    "    ('matrix_builder', builder),\n",
    "    ('classification', classifier)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the dmoz categories\n",
    "In this case, we will just turn the top category in to an index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 7 7 ..., 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "dmoz_encoder = sklearn.preprocessing.LabelEncoder().fit(top_categories)\n",
    "classes = dmoz_encoder.transform(top_categories)\n",
    "X = dmoz_data['meta']\n",
    "print classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the classifier\n",
    "\n",
    "We can use the meta corpus or the full body corpus here, just by replacing a single argument\n",
    "\n",
    "The data is split in to training and test sets, and then fit to the training set. The LDA model is generated ***only*** from the training set, not the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.35 (+/- 0.05)\n"
     ]
    }
   ],
   "source": [
    "scores = sklearn.cross_validation.cross_val_score(clf, X, classes, cv=5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = sklearn.cross_validation.train_test_split(np.array(X), classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45\n"
     ]
    }
   ],
   "source": [
    "model = clf.fit(X_train, y_train)\n",
    "print model.score(X_test, y_test)\n",
    "# model.predict(X_test)\n",
    "# X_test[0].get(\"keyphrases\",[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "category_scores = collections.defaultdict(float)\n",
    "category_counts = collections.defaultdict(float)\n",
    "for real, pred in sorted(zip(dmoz_encoder.inverse_transform(y_test), dmoz_encoder.inverse_transform(model.predict(X_test)))):\n",
    "    category_scores[real] += 1 if real == pred else 0\n",
    "    category_counts[real] += 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the score for each category. \n",
    "\n",
    "Note that if the classifier assigned *random* categories, the score would be $\\frac{1}{\\textrm{num categories}}$. Instead, it is actually quite high in some cases, indicating a moderate amount of success (given how naive this is!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/num_cats =  0.0666666666667 \n",
      "\n",
      "Category       Proportion   Score\n",
      "---------------------------------\n",
      "arts            0.04833      0.2069\n",
      "regional        0.003333      0.0  \n",
      "shopping        0.045        0.2593\n",
      "reference       0.07667      0.3478\n",
      "business        0.08667      0.3846\n",
      "kids and teens  0.02333      0.2143\n",
      "computers       0.08333      0.42 \n",
      "recreation      0.065        0.359\n",
      "sports          0.1833       0.9  \n",
      "society         0.08167      0.1429\n",
      "health          0.04167      0.24 \n",
      "home            0.06167      0.5676\n",
      "games           0.04         0.4583\n",
      "news            0.06333      0.3947\n",
      "science         0.09667      0.4138\n"
     ]
    }
   ],
   "source": [
    "print \"1/num_cats = \", float(1)/float(15), \"\\n\"\n",
    "print \"Category       Proportion   Score\"\n",
    "print \"---------------------------------\"\n",
    "for cat, proportion, score in [(k, category_counts[k]/len(y_test), category_scores[k] / category_counts[k]) for k in category_counts.keys()]:\n",
    "    print \"{:<15} {:<7.4}      {:<5.4}\".format(cat, proportion, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
