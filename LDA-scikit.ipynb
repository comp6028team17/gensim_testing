{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lib import jsoncorpus, datastuff\n",
    "import gensim\n",
    "import traceback\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.pipeline\n",
    "import sklearn.preprocessing\n",
    "import sklearn.cross_validation\n",
    "import sklearn.ensemble\n",
    "from lib.scikitComponents import *\n",
    "import itertools\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Load in the previously created corpus and dictionary of scraped sites\n",
    "dictionary, corpus, meta_corpus, dmoz_data = jsoncorpus.load_or_create('docs/sites.jl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build a list of all topics\n",
    "allcategories = set(tuple(t) for t in dmoz_data['dmoz_categories'])\n",
    "# Build a list of all top-level topics\n",
    "topcategories = set(topic[0] for topic in dmoz_data['dmoz_categories'])\n",
    "# Link topics to URLs\n",
    "meta = list(zip(dmoz_data['urls'], dmoz_data['dmoz_categories']))\n",
    "# Represent the topics in an alternative way\n",
    "heirarchal_categories = lambda max_depth: [['; '.join(topics[:ti+1]) for ti, t in enumerate(topics) if ti < max_depth] for topics in dmoz_data['dmoz_categories']]\n",
    "# Top categories\n",
    "top_categories = [x[0] for x in heirarchal_categories(1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a classification pipeline for the corpus data\n",
    "\n",
    "The Pipeline() object chains together objects from the lib.scikitComponents file, so that they can be used as part of a scikit-learn classification pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lda_feature_pipeline(num_topics):\n",
    "    return sklearn.pipeline.Pipeline([\n",
    "            ('lda_model', LDAModel(dictionary, num_topics)),\n",
    "            ('matrix_builder', TopicMatrixBuilder(num_topics))\n",
    "            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a classifier (decision trees), and chain the preprocessing step to the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trees = sklearn.ensemble.ExtraTreesClassifier(random_state=0, n_estimators=100, oob_score=True, bootstrap=True, n_jobs=4)\n",
    "clf = sklearn.pipeline.Pipeline([\n",
    "    ('preprocess_meta', lda_feature_pipeline(len(topcategories))),\n",
    "    ('classification', trees)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the dmoz categories\n",
    "In this case, we will just turn the top category in to an index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 7 7 ..., 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "dmoz_encoder = sklearn.preprocessing.LabelEncoder().fit(top_categories)\n",
    "classes = encoder.transform(top_categories)\n",
    "print classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the classifier\n",
    "\n",
    "We can use the meta corpus or the full body corpus here, just by replacing a single argument\n",
    "\n",
    "The data is split in to training and test sets, and then fit to the training set. The LDA model is generated ***only*** from the training set, not the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sklearn.cross_validation.cross_val_score(clf, meta_corpus, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = sklearn.cross_validation.train_test_split(np.array(meta_corpus), classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.246666666667\n"
     ]
    }
   ],
   "source": [
    "model = clf.fit(X_train, y_train)\n",
    "print model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "category_scores = collections.defaultdict(float)\n",
    "category_counts = collections.defaultdict(int)\n",
    "for real, pred in sorted(zip(encoder.inverse_transform(y_test), encoder.inverse_transform(model.predict(X_test)))):\n",
    "    category_scores[real] += 1 if real == pred else 0\n",
    "    category_counts[real] += 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the score for each category. \n",
    "\n",
    "Note that if the classifier assigned *random* categories, the score would be $\\frac{1}{\\textrm{num categories}}$. Instead, it is actually quite high in some casses, indicating a moderate ammount of succcess (given how naive this is!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'arts': 0.1794871794871795,\n",
       " u'business': 0.2777777777777778,\n",
       " u'computers': 0.2553191489361702,\n",
       " u'games': 0.0,\n",
       " u'health': 0.1724137931034483,\n",
       " u'home': 0.15151515151515152,\n",
       " u'kids and teens': 0.0625,\n",
       " u'news': 0.1891891891891892,\n",
       " u'recreation': 0.05405405405405406,\n",
       " u'reference': 0.13333333333333333,\n",
       " u'regional': 0.0,\n",
       " u'science': 0.18518518518518517,\n",
       " u'shopping': 0.125,\n",
       " u'society': 0.0,\n",
       " u'sports': 0.5086206896551724}"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "{k: category_scores[k] / category_counts[k] for k in category_counts.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
